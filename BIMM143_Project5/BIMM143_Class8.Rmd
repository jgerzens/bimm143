---
title: "BIMM143 Class8"
author: "Jacob Gerzenshtein"
date: "April 26, 2018"
output:
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Machine Learning with kmeans

Setting up some data  

```{r}
tmp <- c(rnorm(30, -3), rnorm(30,3))
x <- cbind (x = tmp, r = rev(tmp))

plot(x)
```

Using the kmeans() function 

```{r}
km <- kmeans(x, centers = 2, nstart = 20)
km
```

Analyzing km 

```{r}
km$cluster

km$size

km$centers
```

Plotting it 

```{r}
plot(x, col = km$cluster)
points(km$centers, col = "Blue", pch = 12)
```

Doing it with k = 3

```{r}
km2 <- kmeans(x, centers = 3, nstart = 20)
km2 
```

Analyzing km3

```{r}
km2$cluster
km$size
km$centers
```
Plotting it

```{r}
plot(x, col = km2$cluster)
points(km$centers, col = "Blue", pch = 12)
```


## Machine Learning with Hierarchical clustering model  

Coding it: 

```{r}
dist_matrix <- dist(x)

#dist_matrix

hc <- hclust (d = dist_matrix)

```

Now looking at the distance matrix 

```{r}
class(dist_matrix)
```


Looking at it 
```{r}
View(as.matrix(dist_matrix))
dim(as.matrix(dist_matrix))
```

```{r}
plot(hc)
abline(h = 4, col = "red")
cutree(hc, k = 6)
```

```{r}
plot(x, col = cutree(hc, k = 5))
points(km2$centers, col = "blue", pch = 12)
print(km2$centers)
```

Different clusters: 

```{r}
#hc.complete <- hclust(x, method = "complete")

```

```{r}
x <- rbind(
  matrix(rnorm(100, mean = 0, sd = 0.3), ncol = 2),
  matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2),
  matrix(c(rnorm(50, mean = 1, sd = 0.3),
          rnorm(50, mean = 0, sd = 0.3)), ncol = 2))

colnames(x) <- c("x", "y")

plot(x)

col <- as.factor(rep(c("c1", "c2", "c3"), each = 50))

plot(x, col = col)

plot (x, col=cutree(hc, k = 3))

```


```{r}

x <- rbind(
  matrix(rnorm(100, mean = 0, sd = 0.3), ncol = 2),
  matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2),
  matrix(c(rnorm(50, mean = 1, sd = 0.3),
          rnorm(50, mean = 0, sd = 0.3)), ncol = 2))


matrix2 <- dist(x)

hc2 <- hclust (d = matrix2)

plot(hc2)

abline(h = 2, col = "red")

cutree(hc2, k = 3)

plot(x, col = cutree(hc2, k = 3))

```

## PCA time 

```{r}
mydata <- matrix(nrow = 100, ncol = 10)
rownames(mydata) <- paste("gene", 1:100, sep = "")
colnames(mydata) <- c(paste("wt", 1:5, sep = ""),
                      paste("ko", 1:5, sep = ""))
for (i in 1:nrow(mydata)) {
  wt.values <- rpois(5, lambda = sample(x = 10:1000, size = 1))
  ko.values <- rpois(5, lambda = sample(x = 10:1000, size = 1))
  
  mydata[i, ] <- c(wt.values, ko.values)
  
}

head(mydata)


pca <- prcomp(t(mydata), scale = TRUE)

attributes(pca)

plot(pca$x[ ,1], pca$x [ ,2])

pca.var <- pca$sdev^2

pca.var.per <- round(pca.var/sum(pca.var) * 100, 1)

pca.var.per

barplot(pca.var.per, main = "Scree Plot", 
        xlab = "Principal Component", ylab = "Percent Variation")

colvec <- colnames(mydata)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"


plot(pca$x[ ,1], pca$x[ ,2], col = colvec, pch = 16,
     xlab = paste0("PC1 (", pca.var.per[1], "%)"),
     ylab = paste0("PC2 (", pca.var.per[2], "%)"))

# run in console to identify points:
# identify(pca$x[ ,1], pca$x[ ,2], labels = colnames(mydata))


```


